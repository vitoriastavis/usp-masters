---
title: "vitoria-project"
author: "vitoria"
date: "2025-04-02"
output: html_document
---

# Load libraries

```{r message=FALSE, warning=FALSE}
# List of libraries to install
libraries <- c("dplyr", "httr2", "jsonlite", "ggplot2", "readxl", "rvest", 
               "readr", "stringr", "tidyr", "scales", "httr", "xml2", "data.table")




if (!require("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
if (!require("biomaRt", quietly = TRUE)){
  BiocManager::install(c('mygene', 'biomaRt'))
}


# Function to install missing libraries
install_if_missing <- function(lib) {
  if (!require(lib, character.only = TRUE)) {
    install.packages(lib, dependencies = TRUE)
    library(lib, character.only = TRUE)
  }
}

# Apply the function to all libraries
sapply(libraries, install_if_missing)
```

```{r message=FALSE, warning=FALSE}
library(dplyr)
library(httr2)
library(jsonlite)
library(ggplot2)
library(readxl)
# library(rvest)
library(readr)
library(stringr)
library(tidyr)
library(scales)
library(httr)
library(xml2)
library(biomaRt)
library(openxlsx)
library(mygene)
library(data.table)

```

# Target prediction
## Functions to get SMILES from CID

```{r message=FALSE, warning=FALSE}
# Try to get CID from compound name
# If not possible, try to get CID from SID
# Param - name: compound name (character)
# Return - compound_cid: CID (integer)
get_cid <- function(name) {
  if (is.na(name) || name == "") return(NA)  # Handle missing names
  
  encoded_name <- URLencode(name, reserved = TRUE)
  
  # Try getting CID using compound name endpoint
  url_cid <- paste0("https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/name/", 
                    encoded_name, "/cids/JSON")
  response_cid <- tryCatch({
    req <- request(url_cid) |> req_perform()
    if (resp_status(req) == 200) {
      data <- resp_body_json(req)
      if (!is.null(data$IdentifierList$CID)) {
        compound_id <- data$IdentifierList$CID[[1]]
        returncompound_id  # Return first CID
      }
    }
    return(NA)
  }, error = function(e) return(NA))
  
  # If a CID was found, return it immediately
  if (!is.na(response_cid)) {
    return(response_cid)
  }
  
  # Pause to respect API rate limits
  Sys.sleep(0.5)  
  
  # Try getting SID using substance name endpoint
  url_sid <- paste0("https://pubchem.ncbi.nlm.nih.gov/rest/pug/substance/name/", encoded_name, "/sids/JSON")
  response_sid <- tryCatch({
    req <- request(url_sid) |> req_perform()
    if (resp_status(req) == 200) {
      data <- resp_body_json(req)
      if (!is.null(data$IdentifierList$SID) && length(data$IdentifierList$SID) > 0) {
        data$IdentifierList$SID[[1]]  # Store the SID 
      } else {
        NA
      }
    } else {
      NA
    }
  }, error = function(e) return(NA))
  
  # Pause to respect API rate limits
  Sys.sleep(0.5)  
  
  # Try getting CID using SID
  url_sid_cid <- paste0("https://pubchem.ncbi.nlm.nih.gov/rest/pug/substance/sid/", 
                        response_sid, "/JSON")
  response_cid <- tryCatch({
    req <- request(url_sid_cid) |> req_perform()
    if (resp_status(req) == 200) {
      data <- resp_body_json(req)
      if (!is.null(data$PC_Substances[[1]]$compound[[2]]$id$id$cid) && length(data$PC_Substances[[1]]$compound[[2]]$id$id$cid) > 0) {
        # print("Found CID using SID") 
        compound_id <- data$PC_Substances[[1]]$compound[[2]]$id$id$cid[[1]]
        return(compound_id)  # Return CID
      } 
    }
    return(NA)
  }, error = function(e) return(NA))
}

# Get SMILES from Compound ID
# Param - compound_id: CID (integer) 
# Return (character): SMILES for the compound
library(httr2)
library(jsonlite)

library(httr2)
library(xml2)

get_smiles_from_cid <- function(compound_id) {
  tryCatch({
    if (is.na(compound_id) || compound_id == "") return(NA)

    # URL com /property
    url_property <- paste0("https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/cid/", compound_id, "/property/CanonicalSMILES/JSON")
    req_prop <- request(url_property)

    # Verifica se a URL responde 200 OK
    status_check <- tryCatch({
      req_prop_head <- req_prop |> req_method("HEAD")
      resp_head <- req_perform(req_prop_head)
      resp_status(resp_head)
    }, error = function(e) return(NA))

    if (!is.na(status_check) && status_check == 200) {
      # Faz a requisição completa
      resp <- req_perform(req_prop)
      json <- resp_body_json(resp)
      smiles <- json$PropertyTable$Properties[[1]]$CanonicalSMILES
      if (!is.null(smiles)) return(smiles)
    }
    
    print("nao achei no property, vou no XML")

    # Se a URL não existir ou não retornar smiles → busca no XML
    url_xml <- paste0("https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/cid/", compound_id, "/record/XML")
    req_xml <- request(url_xml)
    resp_xml <- req_perform(req_xml)
    xml <- read_xml(resp_body_string(resp_xml))

    node <- xml_find_first(
      xml,
      "//PC-InfoData[
         PC-InfoData_urn/PC-Urn/PC-Urn_label='SMILES' and
         PC-InfoData_urn/PC-Urn/PC-Urn_name='Absolute'
       ]/PC-InfoData_value/PC-InfoData_value_sval"
    )
    
    print(xml_text(node))

    if (!is.na(node)) return(xml_text(node))

    return(NA)
  }, error = function(e) {
    message("Erro com CID: ", compound_id)
    return(NA)
  })
}


```

## Read and preprocess the data from gutMGene

```{r}
# Read the CSV file from gutMGene
gutmgene1 <- read.csv("data/gutmgene/gutmgene.csv", stringsAsFactors = FALSE)
gutmgene2 <- read.csv("data/gutmgene/gutmgene2.csv", stringsAsFactors = FALSE)

# gutmgene_mouse <- read.csv("data/gutmgene/gutmgene_mouse.csv", stringsAsFactors = FALSE)
# gutmgene_mouse2 <- read.csv("data/gutmgene/gutmgene_mouse.csv", stringsAsFactors = FALSE)
# gutmgene_microbe <- read.csv("data/gutmgene/gutmgene_gutmicrobe.csv", stringsAsFactors = FALSE)


# Rename columns to avoid special character issues
colnames(gutmgene1) <- c("Host_Species", "Gut_Microbe_ID", "Rank",
                        "Metabolite_ID", "Evidence_Type", "Evidence_Amount")
colnames(gutmgene2) <- c("Host_Species", "Metabolite_ID", "Gene_ID",
                        "Alteration", "Evidence_Type", "Evidence_Amount")

# Extract the metabolite name from the "Metabolite_ID" column
# and microbe name from "Gut_Microbe_ID"
gutmgene1 <- gutmgene1 %>%
  mutate(
    Metabolite_Name = str_remove(Metabolite_ID, "\\([^()]*\\)$"), # Removes last set of parentheses and content
    Metabolite_Name = str_trim(Metabolite_Name), # Trims whitespace
    Gut_Microbe_Name = str_extract(Gut_Microbe_ID, "^[^(]+"), # Extracts text before '('
    Gut_Microbe_ID = as.integer(str_extract(Gut_Microbe_ID, "(?<=\\().*(?=\\))")), # Extracts numbers inside '()'
  )

gutmgene2 <- gutmgene2 %>% 
  mutate(
    Metabolite_Name = str_remove(Metabolite_ID, "\\([^()]*\\)$"), # Removes last set of parentheses and content
    Metabolite_Name = str_trim(Metabolite_Name) # Trims whitespace
  )


# Remove a possibly incorrect microorganism (it's actually an insect)
gutmgene1 <- gutmgene1[!grepl("Bacteria Latreille et al. 1825", gutmgene1$Gut_Microbe_Name), ]
# Remove not identified species?
gutmgene1 <- gutmgene1[!grepl("CEBAS", gutmgene1$Gut_Microbe_Name), ]

only_gutmgene2 <- setdiff(gutmgene2$Metabolite_Name, gutmgene1$Metabolite_Name)
diff_cid <- unname(sapply(only_gutmgene2, get_cid_vec))

# How many metabolites
cat("N metabolites (repeated):",
    length(gutmgene$Metabolite_ID), "\n")
cat("N metabolites (unique):",
    length(unique(gutmgene$Metabolite_ID)), "\n")

# Number of unique species
unique_species_count <- gutmgene %>% filter(Rank == 'species') %>%
  summarise(count = n_distinct(Gut_Microbe_ID)) %>% pull(count)
cat("N unique microbe IDs for species:", unique_species_count, "\n")

# Number of unique genera
gutmgene$Microbe_Genus <- sub(" .*", "", gutmgene$Gut_Microbe_Name)
gutmgene$Microbe_Genus <- gsub("\\[|\\]", "", gutmgene$Microbe_Genus)
cat("N unique genera:", length(unique(gutmgene$Microbe_Genus)), "\n")
```

## Build plots of raw data

### Plot 1 - Distribution of genera among metabolites

```{r}
# Count occurrences of each genus
genus_counts <- table(gutmgene$Microbe_Genus)

# Filter to only include genera with frequency > 5
genera_to_keep <- names(genus_counts[genus_counts >= 5])
gutmgene_filtered <- gutmgene[gutmgene$Microbe_Genus %in% genera_to_keep, ]

# Order from most frequent to less frequent
gutmgene_filtered_count <- gutmgene_filtered %>%
  count(Microbe_Genus) %>%
  mutate(Microbe_Genus = reorder(Microbe_Genus, -n))

title_portuguese <- "Distribuição dos microorganismos da microbiota intestinal"
x_axis_portuguese <- "Microorganismo (gênero)"
y_axis_portuguese <- "Número de metabólitos produzidos"

# Create the plot
microbe_distribution <- ggplot(gutmgene_filtered_count,
                               aes(x = Microbe_Genus, y = n)) +
  geom_bar(stat = "identity", fill = "gray30", width = 0.5) +
  theme_minimal() + 
  ggtitle(title_portuguese) +  
  theme(
    plot.title = element_text(size = 18, hjust = 0.5),  
    axis.title.y = element_text(size = 16),
    axis.title.x = element_text(size = 16),
    axis.text.y = element_text(size = 16),
    axis.text.x = element_text(size = 16, angle = 60, hjust = 1),
    panel.grid = element_blank(),  # Remove grid lines
    axis.line.x = element_line(color = "black", linewidth = 0.5),  # Only X-axis line
    axis.line.y = element_line(color = "black", linewidth = 0.5),  # Only Y-axis line
    axis.ticks = element_line(color = "black", linewidth = 1)      # Ensure ticks are visible
  ) +
  labs(x = x_axis_portuguese, 
       y = y_axis_portuguese) +
  scale_y_continuous(breaks = seq(0,max(gutmgene_filtered_count$n),
                                  by = 5))
# Create a directory for plots if it doesn't exist
if (!dir.exists("plots")) {
  dir.create("plots")
}

# Save plot as PNG
png("plots/gutmgene/microbe_distribution.png", width = 800, height = 500)
print(microbe_distribution)
dev.off()
```

## Clean the data

```{r}

# Concatenate dataframes
common_cols <- intersect(names(gutmgene1), names(gutmgene2))
gutmgene <- bind_rows(
  select(gutmgene1, all_of(common_cols)),
  select(gutmgene2, all_of(common_cols))
)

cat("N metabolites (unique):",
    length(unique(gutmgene$Metabolite_ID)), "\n")

# Parse Compound ID (CID)
# with vectorized function
get_cid_vec <- Vectorize(get_cid)
gutmgene <- gutmgene %>%
  mutate(
    Metabolite_CID = get_cid_vec(Metabolite_Name) # Obtains CID for the metabolite name
  )


# Remove NAs
if (nrow(gutmgene %>% filter(is.na(Metabolite_CID))) != 0) {
  gutmgene_na <- gutmgene %>% filter(is.na(Metabolite_CID))
  cat("Removed", nrow(gutmgene_na), "Metabolite_CID NAs\n")
} else {
  gutmgene_clean <- gutmgene
  gutmgene_na <- data.frame()
  cat("No Metabolite_CID NAs found\n")
}

cat("N metabolites before removing duplicates:", length(gutmgene$Metabolite_CID), "\n")
# Remove duplicates
gutmgene_nodup <- gutmgene_clean %>%
  distinct(Metabolite_CID, .keep_all=TRUE)
cat("N metabolites without duplicates:", length(gutmgene_nodup$Metabolite_CID), "\n")

# Save processed dataframe
save(gutmgene_nodup, file = "data/gutmgene_nodup.RData")  # No duplicated metabolites
save(gutmgene_na, file = "data/gutmgene_na.RData")        # Only the NAs
```

## Get SMILES

```{r}
library(httr)
library(jsonlite)

get_smiles_from_pubchem <- function(compound_id) {
  library(httr)
  library(jsonlite)

  url <- paste0("https://pubchem.ncbi.nlm.nih.gov/rest/pug_view/data/compound/", compound_id, "/JSON")
  res <- try(GET(url), silent = TRUE)

  if (inherits(res, "try-error") || status_code(res) != 200) {
    return(NA)
  }

  parsed <- try(fromJSON(content(res, as = "text", encoding = "UTF-8"), simplifyVector = FALSE), silent = TRUE)
  if (inherits(parsed, "try-error") || is.null(parsed$Record$Section)) {
    return(NA)
  }

  find_smiles <- function(sections) {
    for (sec in sections) {
      if (is.list(sec) && !is.null(sec$TOCHeading) && sec$TOCHeading == "SMILES") {
        for (info in sec$Information) {
          val <- info$Value$StringWithMarkup[[1]]$String
          if (!is.null(val)) return(val)
        }
      }
      if (is.list(sec) && !is.null(sec$Section)) {
        found <- find_smiles(sec$Section)
        if (!is.null(found)) return(found)
      }
    }
    return(NULL)
  }

  smiles <- find_smiles(parsed$Record$Section)
  return(ifelse(is.null(smiles), NA, smiles))
}

smiles <- sapply(diff_cid, get_smiles_from_pubchem)
# Create dataframe to store SMILES and CIDs for target prediction
df_smiles_ids <- data.frame(SMILES=smiles,
                         pubchem_ids=paste0("cid", diff_cid),
                         stringsAsFactors=FALSE)
# Save the dataframe as text file
write.table(df_smiles_ids, file="smiles_others.txt",
            row.names=FALSE, col.names=FALSE,
            quote=FALSE, sep=" ")
```

```{r}
# Run the get_smiles_from_cid() for each metabolite CID
smiles <- sapply(gutmgene_nodup$Metabolite_CID, get_smiles_from_cid)
cat(length(smiles), "SMILES were obtained\n")

# Create dataframe to store SMILES and CIDs for target prediction
df_smiles_ids <- data.frame(SMILES=smiles,
                         pubchem_ids=paste0("cid", gutmgene_nodup$Metabolite_CID),
                         stringsAsFactors=FALSE)
# Save the dataframe as text file
write.table(df_smiles_ids, file="smiles_ids.txt",
            row.names=FALSE, col.names=FALSE,
            quote=FALSE, sep=" ")

# Create dataframe to store names and CIDs of the metabolites 
# that are not on PubChem to find the SMILES by the name
df_names_ids <- data.frame(name=gutmgene_na$Metabolite_Name,
                         pubchem_id=paste0("nocid", 1:length(gutmgene_na$Metabolite_Name)),
                         stringsAsFactors=FALSE)
# Save the dataframe as text file
write.table(df_names_ids, file="names_ids.txt",
            row.names=FALSE, col.names=FALSE,
            quote=FALSE, sep=" ")
```

## Parsing SEA results

After running SEA with smiles_ids.txt, read the results.

```{r}
# Read SEA dataframe
original <- read.csv("data/target_prediction/sea/original.xls")
extra <- read.csv("data/target_prediction/sea/extra.xls")
combined <- rbind(original, extra)
# write.xlsx(combined, "data/target_prediction/sea/sea-combined.xlsx")

# Rename columns to avoid special character issues
sea_result <- combined
colnames(sea_result) <- c("Query_ID", "Target_ID", "Affinity_Threshold", "P_Value",
                          "Max_Tc", "Cut_Sum", "Z_Score", "Name", "Description", "Query_Smiles")

# Get only the human targets 
sea_result <- sea_result[grepl("_HUMAN$", sea_result$Target_ID), ]

# Sort the data frame by Target_ID and then by P_Value (ascending)
sea_result <- sea_result[order(sea_result$Target_ID, sea_result$P_Value), ]
# Keep only the first occurrence of each Target_ID (which now has the lowest P_Value)
sea_result <- sea_result[!duplicated(sea_result$Target_ID), ]

sea_targets <- sea_result$Target_ID
sea_targets <- gsub("_HUMAN", "", sea_targets)
cat(length(sea_targets), "targets were predicted with SEA\n")

```

## Parsing STP results

```{r}
# Directory with STP .csv files
directory <- "data/target_prediction/stpnovo"

# Get the files
files <- list.files(path = directory, pattern = "\\.csv$", full.names = TRUE)

# Iterate over the files creating dataframes
dataframes <- list()
for (file_path in files) {
  if (file.info(file_path)$size > 0) {
    df <- read_csv(file_path, show_col_types = FALSE)
    dataframes[[length(dataframes) + 1]] <- df
  } else {
    cat("No targets predicted:", basename(file_path), "\n")
  }
}

# Concatenate dataframes
stp_result <- bind_rows(dataframes)

# Write final dataframe
write_csv(stp_result_extra, file.path(directory, "stp_results.csv"))
```

```{r}
# Read STP dataframe
stp_result <- read.csv("data/target_prediction/stpnovo/stp_results.csv")

# Rename columns to avoid special character issues
colnames(stp_result) <- c("Name", "Common_name", "Uniprot_ID",
                          "ChEMBL_ID", "Class",
                          "Probability", "Known_Actives")

# Remove targets with probability = 0
stp_result <- stp_result[stp_result$Probability != 0, ]

# # Filter the rows with higher probability
stp_result <- stp_result[order(stp_result$Common_name, stp_result$Probability), ]

# Get unique targets
stp_result <- stp_result %>% distinct(Common_name, .keep_all=TRUE)
stp_targets <- stp_result$Common_name  

cat(length(stp_targets), "targets were predicted with STP\n")
```

```{r}
mart <- useMart("ensembl", dataset="hsapiens_gene_ensembl")
# Vetor de filtros que você quer testar
filtros <- c("hgnc_symbol", "chembl", "embl", "entrezgene_id", 
             "ensembl_gene_id", "external_gene_name", 
             "hgnc_id", "hpa_id", "hpa_accession")

# Lista para guardar os resultados
resultado_lista <- list()

# Loop por cada filtro
for (filtro in filtros) {
  resultado <- tryCatch({
    getBM(
      attributes = c("hgnc_symbol"),
      filters = filtro,
      values = sea_targets,
      mart = mart
    )
  }, error = function(e) {
    message(paste("Erro com filtro:", filtro))
    return(NULL)
  })
  
  # Guardar o resultado na lista
  resultado_lista[[filtro]] <- resultado$hgnc_symbol
}
ensembl_sea <- unique(na.omit(unlist(resultado_lista)))
#######################################################################
# Lista para guardar os resultados
resultado_lista <- list()

# Loop por cada filtro
for (filtro in filtros) {
  resultado <- tryCatch({
    getBM(
      attributes = c("hgnc_symbol"),
      filters = filtro,
      values = stp_targets,
      mart = mart
    )
  }, error = function(e) {
    message(paste("Erro com filtro:", filtro))
    return(NULL)
  })
  
  # Guardar o resultado na lista
  resultado_lista[[filtro]] <- resultado$hgnc_symbol
}
ensembl_stp <- unique(na.omit(unlist(resultado_lista)))
#######################################################################

map_to_hgnc_flexible <- function(targets) {
  # Baixar o dataset da HGNC (salvo localmente para evitar sobrecarga)
  hgnc_url <- "https://storage.googleapis.com/public-download-files/hgnc/tsv/tsv/hgnc_complete_set.txt"
  hgnc_file <- tempfile(fileext = ".tsv")
  download.file(hgnc_url, hgnc_file, quiet = TRUE)
  hgnc <- fread(hgnc_file, sep = "\t", quote = "")

  # Expandir aliases e nomes anteriores
  expand_aliases <- function(x) unique(unlist(strsplit(x, "\\|")))

  # Construir data.table com todas as formas de nomes
  expanded <- rbindlist(list(
    data.table(input = expand_aliases(hgnc$symbol), hgnc_symbol = hgnc$symbol),
    data.table(input = unlist(sapply(hgnc$alias_symbol, expand_aliases)), hgnc_symbol = hgnc$symbol),
    data.table(input = unlist(sapply(hgnc$prev_symbol, expand_aliases)), hgnc_symbol = hgnc$symbol),
    data.table(input = hgnc$name, hgnc_symbol = hgnc$symbol)
  ), use.names = TRUE, fill = TRUE)

  expanded <- unique(expanded[!is.na(input)])

  # Normalizar input
  targets_clean <- toupper(trimws(targets))

  # Mapear
  mapped <- expanded[input %in% targets_clean]
  unique(mapped$hgnc_symbol)
}

hgncdataset_sea <- map_to_hgnc_flexible(sea_targets)
hgncdataset_stp <- map_to_hgnc_flexible(stp_targets)

  
#######################################################################
  
library(hgnc)
library(lubridate)
library(hgnc)

# Baixa a base HGNC
hgnc_tbl <- import_hgnc_dataset()
safe_crosswalk <- function(value, from, to = "symbol", hgnc_dataset) {
  tryCatch({
    crosswalk(value = value, from = from, to = to, hgnc_dataset = hgnc_dataset)
  }, error = function(e) {
    NULL
  })
}

# Loop em todas as colunas
results <- list()
for (col in colnames(hgnc_tbl)) {
  cat("Tentando coluna:", col, "\n")
  res <- safe_crosswalk(value = sea_targets, from = col, to = "symbol", hgnc_dataset = hgnc_tbl)
  if (!is.null(res) && length(res) > 0) {
    results[[col]] <- res
  }
}
hgnc_sea <- unique(na.omit(unlist(results)))


# Loop em todas as colunas
results <- list()
for (col in colnames(hgnc_tbl)) {
  # cat("Tentando coluna:", col, "\n")
  res <- safe_crosswalk(value = stp_targets, from = col, to = "symbol", hgnc_dataset = hgnc_tbl)
  if (!is.null(res) && length(res) > 0) {
    results[[col]] <- res
  }
}
hgnc_stp <- unique(na.omit(unlist(results)))

#######################################################################
map_to_hgnc <- function(targets) {
  res <- queryMany(targets, scopes = "symbol,alias,name", fields = "symbol", species = "human")
  unique(res$symbol[!is.na(res$symbol)])
}

mygene_sea <- map_to_hgnc(sea_targets)  
mygene_stp <- map_to_hgnc(stp_targets)   

#######################################################################

all_sea <- Reduce(union, list(ensembl_sea, hgncdataset_sea, hgnc_sea, mygene_sea))
write.csv(all_sea, "data/target_prediction/sea/sea_targets.csv", row.names = FALSE)

all_stp <- Reduce(union, list(ensembl_stp, hgncdataset_stp, hgnc_stp, mygene_stp))
write.csv(all_stp, "data/target_prediction/stpnovo/stp_targets.csv", row.names = FALSE)

targets_intersection <- intersect(all_sea, all_stp)
save(targets_intersection, file='data/target_prediction/targets_intersection.RData')

```

# Getting the predicted metabolites/ligands for the intersection genes

```{r}
sea_result <- read.csv("data/target_prediction/sea/sea_results.xls")

# Rename columns to avoid special character issues
colnames(sea_result) <- c("Query_ID", "Target_ID", "Affinity_Threshold", "P_Value",
                          "Max_Tc", "Cut_Sum", "Z_Score", "Name", "Description", "Query_Smiles")

# Get only the human targets 
sea_result <- sea_result[grepl("_HUMAN$", sea_result$Target_ID), ]

NR4A1 <- sea_result[sea_result$Name == "NR4A1", ]
metabolites_NR4A1 <- NR4A1$Query_ID
```

```{r}
library(readxl)
sea_teng <- read_excel("data/teng1.xlsx", col_names = TRUE)
teng_sea <- unique(sea_teng$Name)
cat(length(unique(sea_teng$Metabolite)), length(unique(sea_teng$`Target ID`)))

stp_teng <- read_excel("data/teng2.xlsx", col_names = TRUE)
teng_stp <- unique(stp_teng$`Common name`)

length(unique(stp_teng$`pubchem ID`))

cat(length(unique(stp_teng$Metabolite)), length(unique(stp_teng$`Common name`)))

length(unique(c(stp_teng$Metabolite, sea_teng$Metabolite)))

teng_i <- read_excel("data/teng3.xlsx", col_names = TRUE)$Common


sea_targets <- read.csv("data/target_prediction/sea/sea_targets.csv")$x
stp_targets <- read.csv("data/target_prediction/stpnovo/stp_targets.csv")$x
```
