---
title: "vitoria-project"
author: "vitoria"
date: "2025-04-02"
output: html_document
---

# Load libraries

```{r message=FALSE, warning=FALSE}
# List of libraries to install
libraries <- c("dplyr", "httr2", "jsonlite", "ggplot2", "readxl", "rvest", 
               "readr", "stringr", "tidyr", "scales", "httr", "xml2", "data.table")




if (!require("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
if (!require("biomaRt", quietly = TRUE)){
  BiocManager::install(c('mygene', 'biomaRt'))
}


# Function to install missing libraries
install_if_missing <- function(lib) {
  if (!require(lib, character.only = TRUE)) {
    install.packages(lib, dependencies = TRUE)
    library(lib, character.only = TRUE)
  }
}

# Apply the function to all libraries
sapply(libraries, install_if_missing)
```

```{r message=FALSE, warning=FALSE}
library(dplyr)
library(httr2)
library(jsonlite)
library(ggplot2)
library(readxl)
# library(rvest)
library(readr)
library(stringr)
library(tidyr)
library(scales)
library(httr)
library(xml2)
library(biomaRt)
library(openxlsx)
library(mygene)
library(data.table)

```

# Target prediction
## Functions to get SMILES from CID

```{r message=FALSE, warning=FALSE}
# Try to get CID from compound name
# If not possible, try to get CID from SID
# Param - name: compound name (character)
# Return - compound_cid: CID (integer)
get_cid <- function(name) {
  if (is.na(name) || name == "") return(NA)  # Handle missing names
  
  encoded_name <- URLencode(name, reserved = TRUE)
  
  # Try getting CID using compound name endpoint
  url_cid <- paste0("https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/name/", 
                    encoded_name, "/cids/JSON")
  response_cid <- tryCatch({
    req <- request(url_cid) |> req_perform()
    if (resp_status(req) == 200) {
      data <- resp_body_json(req)
      if (!is.null(data$IdentifierList$CID)) {
        compound_id <- data$IdentifierList$CID[[1]]
        return(compound_id)  # Return first CID
      }
    }
    return(NA)
  }, error = function(e) return(NA))
  
  # If a CID was found, return it immediately
  if (!is.na(response_cid)) {
    print(paste0("found CID for ", name))
    return(response_cid)
  }
  
  # Pause to respect API rate limits
  Sys.sleep(0.5)  
  
  # Try getting SID using substance name endpoint
  url_sid <- paste0("https://pubchem.ncbi.nlm.nih.gov/rest/pug/substance/name/", encoded_name, "/sids/JSON")
  response_sid <- tryCatch({
    req <- request(url_sid) |> req_perform()
    if (resp_status(req) == 200) {
      data <- resp_body_json(req)
      if (!is.null(data$IdentifierList$SID) && length(data$IdentifierList$SID) > 0) {
        data$IdentifierList$SID[[1]]  # Store the SID 
      } else {
        NA
      }
    } else {
      NA
    }
  }, error = function(e) return(NA))
  
  # Pause to respect API rate limits
  Sys.sleep(0.5)  
  
  # Try getting CID using SID
  url_sid_cid <- paste0("https://pubchem.ncbi.nlm.nih.gov/rest/pug/substance/sid/", 
                        response_sid, "/JSON")
  response_cid <- tryCatch({
    req <- request(url_sid_cid) |> req_perform()
    if (resp_status(req) == 200) {
      data <- resp_body_json(req)
      if (!is.null(data$PC_Substances[[1]]$compound[[2]]$id$id$cid) && length(data$PC_Substances[[1]]$compound[[2]]$id$id$cid) > 0) {
        # print("Found CID using SID") 
        compound_id <- data$PC_Substances[[1]]$compound[[2]]$id$id$cid[[1]]
        print(paste0("found CID for ", name))
        return(compound_id)  # Return CID
      } 
    }
    print(paste0("couldn't find CID for ", name))
    return(NA)
  }, error = function(e) return(NA))
}

library(httr2)
library(jsonlite)

library(httr2)
library(xml2)

get_smiles_from_cid <- function(compound_id) {
  tryCatch({
    if (is.na(compound_id) || compound_id == "") return(NA)

    # URL com /property
    url_property <- paste0("https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/cid/", compound_id, "/property/CanonicalSMILES/JSON")
    req_prop <- request(url_property)

    # Verifica se a URL responde 200 OK
    status_check <- tryCatch({
      req_prop_head <- req_prop |> req_method("HEAD")
      resp_head <- req_perform(req_prop_head)
      resp_status(resp_head)
    }, error = function(e) return(NA))

    if (!is.na(status_check) && status_check == 200) {
      # Faz a requisição completa
      resp <- req_perform(req_prop)
      json <- resp_body_json(resp)
      smiles <- json$PropertyTable$Properties[[1]]$CanonicalSMILES
      if (!is.null(smiles)) return(smiles)
    }
    
    print("nao achei no property, vou no XML")

    # Se a URL não existir ou não retornar smiles → busca no XML
    url_xml <- paste0("https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/cid/", compound_id, "/record/XML")
    req_xml <- request(url_xml)
    resp_xml <- req_perform(req_xml)
    xml <- read_xml(resp_body_string(resp_xml))

    node <- xml_find_first(
      xml,
      "//PC-InfoData[
         PC-InfoData_urn/PC-Urn/PC-Urn_label='SMILES' and
         PC-InfoData_urn/PC-Urn/PC-Urn_name='Absolute'
       ]/PC-InfoData_value/PC-InfoData_value_sval"
    )
    
    print(xml_text(node))

    if (!is.na(node)) return(xml_text(node))

    return(NA)
  }, error = function(e) {
    message("Erro com CID: ", compound_id)
    return(NA)
  })
}


```

## Read and preprocess the data from gutMGene

```{r}
# Read the CSV file from gutMGene
gutmgene1 <- read.csv("data/gutmgene/gutmgene.csv", stringsAsFactors = FALSE)
gutmgene2 <- read.csv("data/gutmgene/gutmgene2.csv", stringsAsFactors = FALSE)

# Rename columns to avoid special character issues
colnames(gutmgene1) <- c("Host_Species", "Gut_Microbe_ID", "Rank",
                        "Metabolite_ID", "Evidence_Type", "Evidence_Amount")
colnames(gutmgene2) <- c("Host_Species", "Metabolite_ID", "Gene_ID",
                        "Alteration", "Evidence_Type", "Evidence_Amount")

# Extract the metabolite name from the "Metabolite_ID" column
# and microbe name from "Gut_Microbe_ID"
gutmgene1 <- gutmgene1 %>%
  mutate(
    Metabolite_Name = str_remove(Metabolite_ID, "\\([^()]*\\)$"), # Removes last set of parentheses and content
    Metabolite_Name = str_trim(Metabolite_Name), # Trims whitespace
    Gut_Microbe_Name = str_extract(Gut_Microbe_ID, "^[^(]+"), # Extracts text before '('
    Gut_Microbe_ID = as.integer(str_extract(Gut_Microbe_ID, "(?<=\\().*(?=\\))")), # Extracts numbers inside '()'
  )

gutmgene2 <- gutmgene2 %>% 
  mutate(
    Metabolite_Name = str_remove(Metabolite_ID, "\\([^()]*\\)$"), # Removes last set of parentheses and content
    Metabolite_Name = str_trim(Metabolite_Name), # Trims whitespace
    Target_Name = str_remove(Gene_ID, "\\([^()]*\\)$")
  )

gutmgene2 <- gutmgene2 %>%
    mutate(Target_Name = str_trim(Target_Name)) # Trims whitespace

# Remove a possibly incorrect microorganism (it's actually an insect)
gutmgene1 <- gutmgene1[!grepl("Bacteria Latreille et al. 1825", gutmgene1$Gut_Microbe_Name), ]
# Remove not identified species
gutmgene1 <- gutmgene1[!grepl("CEBAS", gutmgene1$Gut_Microbe_Name), ]

# Save data with microbe info
save(gutmgene1, file = "data/gutmgene/gutmgene1_beforemerging.RData")  
```

## Build plots of raw data

### Plot 1 - Distribution of genera among metabolites

```{r}
# Count occurrences of each genus
genus_counts <- table(gutmgene$Microbe_Genus)

# Filter to only include genera with frequency > 5
genera_to_keep <- names(genus_counts[genus_counts >= 5])
gutmgene_filtered <- gutmgene[gutmgene$Microbe_Genus %in% genera_to_keep, ]

# Order from most frequent to less frequent
gutmgene_filtered_count <- gutmgene_filtered %>%
  count(Microbe_Genus) %>%
  mutate(Microbe_Genus = reorder(Microbe_Genus, -n))

title_portuguese <- "Distribuição dos microorganismos da microbiota intestinal"
x_axis_portuguese <- "Microorganismo (gênero)"
y_axis_portuguese <- "Número de metabólitos produzidos"

# Create the plot
microbe_distribution <- ggplot(gutmgene_filtered_count,
                               aes(x = Microbe_Genus, y = n)) +
  geom_bar(stat = "identity", fill = "gray30", width = 0.5) +
  theme_minimal() + 
  ggtitle(title_portuguese) +  
  theme(
    plot.title = element_text(size = 18, hjust = 0.5),  
    axis.title.y = element_text(size = 16),
    axis.title.x = element_text(size = 16),
    axis.text.y = element_text(size = 16),
    axis.text.x = element_text(size = 16, angle = 60, hjust = 1),
    panel.grid = element_blank(),  # Remove grid lines
    axis.line.x = element_line(color = "black", linewidth = 0.5),  # Only X-axis line
    axis.line.y = element_line(color = "black", linewidth = 0.5),  # Only Y-axis line
    axis.ticks = element_line(color = "black", linewidth = 1)      # Ensure ticks are visible
  ) +
  labs(x = x_axis_portuguese, 
       y = y_axis_portuguese) +
  scale_y_continuous(breaks = seq(0,max(gutmgene_filtered_count$n),
                                  by = 5))
# Create a directory for plots if it doesn't exist
if (!dir.exists("plots")) {
  dir.create("plots")
}

# Save plot as PNG
png("plots/gutmgene/microbe_distribution.png", width = 800, height = 500)
print(microbe_distribution)
dev.off()
```

## Clean the data

```{r}
# Concatenate dataframes
common_cols <- intersect(names(gutmgene1), names(gutmgene2))
gutmgene <- dplyr::bind_rows(
  dplyr::select(gutmgene1, all_of(common_cols)),
  dplyr::select(gutmgene2, all_of(common_cols))
)

cat("N metabolites (unique):",
    length(unique(gutmgene$Metabolite_ID)), "\n")

# Parse Compound ID (CID) with vectorized function
get_cid_vec <- Vectorize(get_cid)
gutmgene <- gutmgene %>%
  mutate(
    Metabolite_CID = get_cid_vec(Metabolite_Name) # Obtains CID for the metabolite name
  )

# Remove NAs
if (nrow(gutmgene %>% filter(is.na(Metabolite_CID))) != 0) {
  gutmgene_na <- gutmgene %>% filter(is.na(Metabolite_CID))
  gutmgene_clean <- gutmgene %>% filter(!is.na(Metabolite_CID))
  cat("Removed", nrow(gutmgene_na), "Metabolite_CID NAs\n")
} else {
  gutmgene_clean <- gutmgene
  gutmgene_na <- data.frame()
  cat("No Metabolite_CID NAs found\n")
}

# Remove duplicates
gutmgene_nodup <- gutmgene_clean %>%
  distinct(Metabolite_CID, .keep_all=TRUE)
cat("N metabolites without duplicates:", length(gutmgene_nodup$Metabolite_CID), "\n")

# Save processed dataframe
save(gutmgene_nodup, file = "data/gutmgene/gutmgene_nodup.RData")  # No duplicated metabolites
save(gutmgene_na, file = "data/gutmgene/gutmgene_na.RData")        # Only the NAs

# nao lembro aqui
df <- data.frame(name=gutmgene_nodup$Metabolite_Name,
                         CID=gutmgene_nodup$Metabolite_CID,
                         stringsAsFactors=FALSE)

lines <- readLines("data/gutmgene/names_ids.txt")

# Process each line to extract Name and CID
data <- lapply(lines, function(line) {
  parts <- strsplit(line, " ")[[1]]
  cid <- tail(parts, 1)
  name <- paste(head(parts, -1), collapse = " ")
  return(c(name = name, CID = cid))
})

# Convert the result into a data frame
df2 <- as.data.frame(do.call(rbind, data), stringsAsFactors = FALSE)

df3 <- rbind(df, df2)
write.csv(df3, "data/gutmgene/name_cid.csv", row.names = FALSE)

```

## Get SMILES

```{r}
library(httr)
library(jsonlite)

get_smiles_from_pubchem <- function(compound_id) {
  library(httr)
  library(jsonlite)

  url <- paste0("https://pubchem.ncbi.nlm.nih.gov/rest/pug_view/data/compound/", compound_id, "/JSON")
  res <- try(GET(url), silent = TRUE)

  if (inherits(res, "try-error") || status_code(res) != 200) {
    return(NA)
  }

  parsed <- try(fromJSON(content(res, as = "text", encoding = "UTF-8"), simplifyVector = FALSE), silent = TRUE)
  if (inherits(parsed, "try-error") || is.null(parsed$Record$Section)) {
    return(NA)
  }

  find_smiles <- function(sections) {
    for (sec in sections) {
      if (is.list(sec) && !is.null(sec$TOCHeading) && sec$TOCHeading == "SMILES") {
        for (info in sec$Information) {
          val <- info$Value$StringWithMarkup[[1]]$String
          if (!is.null(val)) return(val)
        }
      }
      if (is.list(sec) && !is.null(sec$Section)) {
        found <- find_smiles(sec$Section)
        if (!is.null(found)) return(found)
      }
    }
    return(NULL)
  }

  smiles <- find_smiles(parsed$Record$Section)
  return(ifelse(is.null(smiles), NA, smiles))
}

smiles <- sapply(diff_cid, get_smiles_from_pubchem)
# Create dataframe to store SMILES and CIDs for target prediction
df_smiles_ids <- data.frame(SMILES=smiles,
                         pubchem_ids=paste0("cid", diff_cid),
                         stringsAsFactors=FALSE)
# Save the dataframe as text file
write.table(df_smiles_ids, file="smiles_others.txt",
            row.names=FALSE, col.names=FALSE,
            quote=FALSE, sep=" ")
```

```{r}
# Run the get_smiles_from_cid() for each metabolite CID
smiles <- sapply(gutmgene_nodup$Metabolite_CID, get_smiles_from_cid)
cat(length(smiles), "SMILES were obtained\n")

# Create dataframe to store SMILES and CIDs for target prediction
df_smiles_ids <- data.frame(SMILES=smiles,
                         pubchem_ids=paste0("cid", gutmgene_nodup$Metabolite_CID),
                         stringsAsFactors=FALSE)
# Save the dataframe as text file
write.table(df_smiles_ids, file="smiles_ids.txt",
            row.names=FALSE, col.names=FALSE,
            quote=FALSE, sep=" ")

# Create dataframe to store names and CIDs of the metabolites 
# that are not on PubChem to find the SMILES by the name
df_names_ids <- data.frame(name=gutmgene_na$Metabolite_Name,
                         pubchem_id=paste0("nocid", 1:length(gutmgene_na$Metabolite_Name)),
                         stringsAsFactors=FALSE)
# Save the dataframe as text file
write.table(df_names_ids, file="names_ids.txt",
            row.names=FALSE, col.names=FALSE,
            quote=FALSE, sep=" ")
```

## Parsing SEA results

After running SEA with smiles_ids.txt, read the results.

```{r}
# Read SEA dataframe
original <- read.csv("data/target_prediction/sea/original.xls")
extra <- read.csv("data/target_prediction/sea/extra.xls")
combined <- rbind(original, extra)
# write.xlsx(combined, "data/target_prediction/sea/sea-combined.xlsx")

# Rename columns to avoid special character issues
sea_result <- combined
colnames(sea_result) <- c("Query_ID", "Target_ID", "Affinity_Threshold", "P_Value",
                          "Max_Tc", "Cut_Sum", "Z_Score", "Name", "Description", "Query_Smiles")

# Get only the human targets 
sea_result <- sea_result[grepl("_HUMAN$", sea_result$Target_ID), ]

# Sort the data frame by Target_ID and then by P_Value (ascending)
sea_result <- sea_result[order(sea_result$Target_ID, sea_result$P_Value), ]
# Keep only the first occurrence of each Target_ID (which now has the lowest P_Value)
sea_result <- sea_result[!duplicated(sea_result$Target_ID), ]

sea_targets <- sea_result$Target_ID
sea_targets <- gsub("_HUMAN", "", sea_targets)
cat(length(sea_targets), "targets were predicted with SEA\n")
```

## Parsing STP results

```{r}
# Directory with STP .csv files
directory <- "data/target_prediction/stpnovo"

# Get the files
files <- list.files(path = directory, pattern = "\\.csv$", full.names = TRUE)

# Iterate over the files creating dataframes
dataframes <- list()
for (file_path in files) {
  if (file.info(file_path)$size > 0) {
    df <- read_csv(file_path, show_col_types = FALSE)
    dataframes[[length(dataframes) + 1]] <- df
  } else {
    cat("No targets predicted:", basename(file_path), "\n")
  }
}

# Concatenate dataframes
stp_result <- bind_rows(dataframes)

# Write final dataframe
write_csv(stp_result_extra, file.path(directory, "stp_results.csv"))
```

```{r}
# Read STP dataframe
stp_result <- read.csv("data/target_prediction/stpnovo/stp_results.csv")

# Rename columns to avoid special character issues
colnames(stp_result) <- c("Name", "Common_name", "Uniprot_ID",
                          "ChEMBL_ID", "Class",
                          "Probability", "Known_Actives")

# Remove targets with probability = 0
stp_result <- stp_result[stp_result$Probability != 0, ]

# # Filter the rows with higher probability
stp_result <- stp_result[order(stp_result$Common_name, stp_result$Probability), ]

# Get unique targets
stp_result <- stp_result %>% distinct(Common_name, .keep_all=TRUE)
stp_targets <- stp_result$Common_name  

cat(length(stp_targets), "targets were predicted with STP\n")
```

## CHEMBL


```{r}
library(readr)
library(dplyr)
# Directory with STP .csv files
directory <- "data/target_prediction/multitask"

# Get the files
files <- list.files(path = directory, pattern = "\\.csv$", full.names = TRUE)

# Iterate over the files creating dataframes
dataframes <- list()
for (file_path in files) {
  df <- read_csv(file_path, show_col_types = FALSE)
  if(dim(df)[1] > 0){
    dataframes[[length(dataframes) + 1]] <- df
  } else {
    cat("No targets predicted:", basename(file_path), "\n")
  }
}

# Concatenate dataframes
multitask_results <- bind_rows(dataframes)

# Write final dataframe
write_csv(multitask_results, file.path(directory, "multitask_results.csv"))
```

```{r}
# Read STP dataframe
multitask_result <- read.csv("data/target_prediction/chemblpred/chemblpred_results.csv")

# Rename columns to avoid special character issues
colnames(multitask_result) <- c("Target_ID", "Probability")

# Remove targets with probability = 0
multitask_result <- multitask_result[multitask_result$Probability != 0, ]

# Filter the rows with higher probability
multitask_result <- multitask_result[order(multitask_result$Target_ID, multitask_result$Probability), ]

# Get unique targets
multitask_result <- multitask_result %>% distinct(Target_ID, .keep_all=TRUE)
multitask_targets <- multitask_result$Target_ID  

# write.table(multitask_targets, file = "data/target_prediction/multitask/multitask_chembl_ids.txt",col.names=FALSE, row.names = FALSE,quote = FALSE)

cat(length(multitask_targets), "targets were predicted with Multitask CHEMBL\n")
```

## PPB2

```{r}
library(readr)
library(dplyr)
# Directory with STP .csv files
directory <- "data/target_prediction/ppb2"

# Get the files
files <- list.files(path = directory, pattern = "\\.txt$", full.names = TRUE)

# Iterate over the files creating dataframes
dataframes_ppb <- list()
for (file_path in files) {
  df <- read_tsv(file_path, show_col_types = FALSE)
  if(dim(df)[1] > 0){
    dataframes_ppb[[length(dataframes_ppb) + 1]] <- as.data.frame(df)
  } else {
    cat("No targets predicted:", basename(file_path), "\n")
  }
}

# Concatenate dataframes
ppb_results <- bind_rows(dataframes_ppb)

# Write final dataframe
write_csv(ppb_results, file.path(directory, "ppb_results.csv"))
```

```{r}
library(dplyr)
# Read STP dataframe
ppb_result <- read.csv("data/target_prediction/ppb2/ppb_results.csv")

# Rename columns to avoid special character issues
colnames(ppb_result) <- c("Rank", "Target_ID", "Common.name")

# Get unique targets
ppb_result <- ppb_result %>% distinct(Target_ID, .keep_all=TRUE)

ppb_targets <- ppb_result$Target_ID 

write.table(ppb_targets, file = "data/target_prediction/ppb2/ppb_chembl_ids.txt",
            col.names = FALSE, row.names = FALSE, quote = FALSE)

cat(length(ppb_targets), "targets were predicted with PPB2")
```

## Mapping

```{r message=FALSE, warning=FALSE}
library(biomaRt)

biomart_mapping <- function(values, 
                            filters_to_try = NULL,
                            mart = NULL,
                            to_attribute = "hgnc_symbol",
                            verbose = FALSE) {
  # Conecta ao Ensembl se não for passado
  if (is.null(mart)) {
    mart <- useMart("ensembl", dataset = "hsapiens_gene_ensembl")
  }

  # Filtros padrão se não forem especificados
  if (is.null(filters_to_try)) {
    filters_to_try <- c(
      "hgnc_symbol", "chembl", "embl", "entrezgene_id", 
      "ensembl_gene_id", "external_gene_name", 
      "hgnc_id", "hpa_id", "hpa_accession", "uniprot_gn_id"
    )
  } else{
    valid_filters <- listFilters(mart)$name
    filters_to_try <- intersect(filters_to_try, valid_filters)
  }
  
  # filters_to_try <- c("uniprot_gn_id")
  # cat(filters_to_try)

  # Lista para guardar os resultados como data frames
  all_results <- list()

  for (filtro in filters_to_try) {
    if (verbose) cat("Tentando filtro:", filtro, "\n")

    res <- tryCatch({
      getBM(
        attributes = c(filtro, to_attribute),
        filters = filtro,
        values = values,
        mart = mart
      )
    }, error = function(e) {
      if (verbose) message("Erro com filtro: ", filtro, " - ", e$message)
      NULL
    })

    if (!is.null(res) && nrow(res) > 0) {
      df <- res
      colnames(df) <- c("Query", "HGNC_ID")
      all_results[[filtro]] <- df
    }
  }

  # Combina tudo em um único data frame
  if (length(all_results) == 0) {
    return(data.frame(Query = character(0), HGNC_ID = character(0)))
  }

  final_df <- do.call(rbind, all_results)
  return(final_df)
}

#######################################################################
library(data.table)

hgnc_dataset_mapping <- function(targets) {
  library(data.table)

  # Baixar dataset HGNC
  hgnc_url <- "https://storage.googleapis.com/public-download-files/hgnc/tsv/tsv/hgnc_complete_set.txt"
  hgnc_file <- tempfile(fileext = ".tsv")
  download.file(hgnc_url, hgnc_file, quiet = TRUE)

  # Ler com segurança
  hgnc <- fread(hgnc_file, sep = "\t", quote = "", fill = TRUE)

  # Garantir colunas necessárias
  cols <- c("symbol", "alias_symbol", "prev_symbol", "name")
  for (col in cols) if (!col %in% names(hgnc)) hgnc[[col]] <- NA_character_

  # Função de expansão
  expand_aliases <- function(symbols, main_symbol) {
    if (is.na(symbols) || symbols == "") return(NULL)
    expanded <- unlist(strsplit(symbols, "\\|"))
    if (length(expanded) == 0) return(NULL)
    data.table(input = toupper(trimws(expanded)), hgnc_symbol = main_symbol)
  }

  safe_rbind <- function(lst) {
    lst <- lst[!sapply(lst, is.null)]
    if (length(lst) == 0) return(data.table(input = character(), hgnc_symbol = character()))
    rbindlist(lst, fill = TRUE)
  }

  # Expandir
  alias_dt  <- safe_rbind(mapply(expand_aliases, hgnc$alias_symbol, hgnc$symbol, SIMPLIFY = FALSE))
  prev_dt   <- safe_rbind(mapply(expand_aliases, hgnc$prev_symbol, hgnc$symbol, SIMPLIFY = FALSE))
  symbol_dt <- data.table(input = toupper(hgnc$symbol), hgnc_symbol = hgnc$symbol)
  name_dt   <- data.table(input = toupper(hgnc$name), hgnc_symbol = hgnc$symbol)

  expanded <- rbindlist(list(symbol_dt, alias_dt, prev_dt, name_dt), fill = TRUE, use.names = TRUE)
  expanded <- unique(expanded[!is.na(input)])

  # Mapeamento
  targets_clean <- toupper(trimws(targets))
  mapped <- expanded[input %in% targets_clean]

  if (nrow(mapped) == 0) {
    warning("Nenhum mapeamento encontrado para os targets fornecidos.")
    return(data.frame(Query = targets, HGNC_ID = NA_character_))
  }

  result <- unique(data.table(Query = mapped$input, HGNC_ID = mapped$hgnc_symbol))
  return(as.data.frame(result))
}

#######################################################################
  
library(hgnc)
library(lubridate)
library(data.table)

hgnc_mapping <- function(values, 
                         from_cols = NULL, 
                         to = "symbol", 
                         hgnc_dataset = NULL, 
                         verbose = FALSE) {
  if (is.null(hgnc_dataset)) {
    if (verbose) cat("Importando base HGNC...\n")
    hgnc_dataset <- import_hgnc_dataset()
  }

  if (is.null(from_cols)) {
    from_cols <- c("hgnc_id", "symbol", "name", "entrez_id", "ensembl_gene_id", "uniprot_ids")
  }
  
  hgnc_long <- setDT(hgnc_dataset)[
    , .(uniprot_id = unlist(strsplit(as.character(uniprot_ids), ",\\s*"))),  # force to character
    by = .(hgnc_id, symbol)
  ]


  # Safe wrapper
  safe_crosswalk <- function(value, from, to, hgnc_dataset) {
    tryCatch({
      crosswalk(value = value, from = from, to = to, hgnc_dataset = hgnc_dataset)
    }, error = function(e) {
      if (verbose) message("Erro na coluna ", from, ": ", e$message)
      NULL
    })
  }

  # Lista para guardar resultados (query, id)
  results_list <- list()

  for (col in from_cols) {
    if (verbose) cat("Tentando coluna:", col, "\n")
    
    if (col == "uniprot_ids") {
      matched <- hgnc_long[uniprot_id %in% values, .(Query = uniprot_id, HGNC_ID = symbol)]
      if (nrow(matched) > 0) results_list[[length(results_list) + 1]] <- matched
    } else {
      for (val in values) {
        res <- tryCatch({
          crosswalk(value = val, from = col, to = to, hgnc_dataset = hgnc_dataset)
        }, error = function(e) {
          if (verbose) message("Erro na coluna ", col, ": ", e$message)
          NULL
        })
        if (!is.null(res) && length(res) > 0) {
          results_list[[length(results_list) + 1]] <- data.frame(Query = val, HGNC_ID = res)
        }
      }
    }
  }

  # Combina tudo e remove duplicatas
  if (length(results_list) == 0) {
    return(data.frame(Query = character(0), HGNC_ID = character(0)))
  }

  final_df <- unique(do.call(rbind, results_list))
  return(final_df)
}

#######################################################################
library(mygene)

mygene_mapping <- function(targets, filters=NULL) {
  
  if(is.null(filters)){
    filters <- "uniprot,entrezgene,symbol,name,hgnc,refseq,alias"
  }
  
  res <- suppressWarnings(
    queryMany(targets, scopes = filters,
              fields = "symbol", species = "human", 
              return.as = "records")
  )
  
  if (is.null(res) || length(res) == 0) {
    return(data.frame(Query = character(0), HGNC_ID = character(0), 
                     stringsAsFactors = FALSE))
  }
  
  # Helper for NULL coalescing
  `%||%` <- function(x, y) if (is.null(x)) y else x
  
  # Process the records format
  queries <- sapply(res, function(x) x$query %||% NA)
  symbols <- sapply(res, function(x) x$symbol %||% NA)
  
  df <- data.frame(
    Query = queries,
    HGNC_ID = symbols,
    stringsAsFactors = FALSE
  )
  
  # Remove rows without valid HGNC mapping (including notfound entries)
  df <- df[!is.na(df$HGNC_ID) & df$HGNC_ID != "" & !is.na(df$Query), , drop = FALSE]
  rownames(df) <- NULL
  
  return(df)
}

#######################################################################

library(httr)
library(jsonlite)
library(biomaRt)
library(UniProt.ws)

# 
chembl_database_mapping <- function(query_targets){
  res <- GET("https://www.ebi.ac.uk/chembl/api/data/target.json?target_type=SINGLE%20PROTEIN&limit=1000")
  data <- fromJSON(httr::content(res, "text"), flatten = TRUE)$targets

  df_uniprot <- data.frame(
    chembl_id = data$target_chembl_id,
    # pref_name = data$pref_name,
    uniprot = sapply(data$target_components, function(x) {
      if (is.data.frame(x) && "accession" %in% names(x)) {
        x$accession[1]   # take the first accession if multiple
      } else {
        NA
      }
    })
  )

  df_uniprot <- df_uniprot[df_uniprot$chembl_id %in% query_targets, ]

  df_biomart <- biomart_mapping(df_uniprot$uniprot, filters_to_try = c("uniprot_gn_id"))

  df_mygene <- mygene_mapping(df_uniprot$uniprot, "uniprot")

  final_df <- rbind(df_biomart, df_mygene)

  return(final_df)
}


#######################################################################

map_hgnc_all_methods <- function(targets, verbose = TRUE) {
  # Run each mapping function with proper error handling
  results <- list()

  # Biomart
  if (verbose) cat("Running biomart_mapping...\n")
  res_biomart <- tryCatch({
    df <- biomart_mapping(targets)
    df$Source <- "biomart"
    df
  }, error = function(e) {
    warning("biomart_mapping failed: ", e$message)
    NULL
  })
  if (!is.null(res_biomart)) results[["biomart"]] <- res_biomart

  # HGNC downloaded dataset
  if (verbose) cat("\nRunning hgnc_dataset_mapping...\n")
  res_dataset <- tryCatch({
    df <- hgnc_dataset_mapping(targets)
    df$Source <- "hgnc_dataset"
    df
  }, error = function(e) {
    warning("hgnc_dataset_mapping failed: ", e$message)
    NULL
  })
  if (!is.null(res_dataset)) results[["hgnc_dataset"]] <- res_dataset

  # hgnc package
  if (verbose) cat("\nRunning hgnc_package\n")
  res_hgnc <- tryCatch({
    df <- hgnc_mapping(targets, verbose)
    df$Source <- "hgnc_package"
    df
  }, error = function(e) {
    warning("hgnc_package failed: ", e$message)
    NULL
  })
  if (!is.null(res_hgnc)) results[["hgnc_package"]] <- res_hgnc

  # mygene
  if (verbose) cat("\nRunning mygene_mapping...\n")
  res_mygene <- tryCatch({
    df <- mygene_mapping(targets)
    
    # Only add Source if df is not empty
    if (nrow(df) > 0) {
      # Remove rownames before adding column
      rownames(df) <- NULL
      df$Source <- "mygene"
      df
    } else {
      message("No HGNC IDs found for these targets")
      NULL
    }
  }, error = function(e) {
    warning("mygene_mapping failed: ", e$message)
    NULL
  })
  if (!is.null(res_mygene)) results[["mygene"]] <- res_mygene
  
  # # CHEMBL
  # if (verbose) cat("\nRunning chembl_database_mapping\n")
  # res_chembl <- tryCatch({
  #   df <- as.data.frame(chembl_database_mapping(targets))
  #   if (nrow(df) > 0) {
  #     # Remove rownames before adding column
  #     rownames(df) <- NULL
  #     df$Source <- "chembl_database"
  #     df
  #   }
  # }, error = function(e) {
  #   warning("chembl_database_mapping failed: ", e$message)
  #   NULL
  # })
  # if (!is.null(res_chembl)) results[["chembl_database"]] <- res_chembl
  # 
  if (verbose) cat("\nCombining results...\n")
  
  # Combine all results
  if (length(results) == 0) {
    return(data.frame(Query = character(0), HGNC_ID = character(0), Source = character(0)))
  }

  combined <- do.call(rbind, results)
  return(combined)
}
```

```{r}
library(readr)

# SEA
sea_mappings <- map_hgnc_all_methods(sea_targets)
all_sea <- unique(sea_mappings$HGNC_ID)
all_sea <- all_sea[!is.na(all_sea)]
write.csv(sea_mappings, "data/target_prediction/sea/sea_mappings.csv", row.names = FALSE)
write.csv(all_sea, "data/target_prediction/sea/sea_targets.csv", row.names = FALSE)

# STP
stp_mappings <- map_hgnc_all_methods(stp_targets)
all_stp <- unique(stp_mappings$HGNC_ID)
all_stp <- all_stp[!is.na(all_stp)]
write.csv(stp_mappings, "data/target_prediction/stpnovo/stp_mappings.csv", row.names = FALSE)
write.csv(all_stp, "data/target_prediction/stpnovo/stp_targets.csv", row.names = FALSE)

# Multitask CHEMBL
multitask_uniprot_ids <- read.table("data/target_prediction/multitask/uniprot_ids_multitask.txt",
                                     header = FALSE,
                                     stringsAsFactors = FALSE) 
multitask_from_chembl_mapping <- chembl_database_mapping(multitask_targets)
multitask_from_chembl_mapping$Source <- "chembl_database"
multitask_from_uniprot_mapping <- map_hgnc_all_methods(multitask_uniprot_ids$V1)
multitask_mappings <- rbind(multitask_from_uniprot_mapping, multitask_from_chembl_mapping)
all_multitask <- unique(all_multitask$HGNC_ID)
all_multitask <- all_multitask[!is.na(all_multitask)]
write.csv(multitask_mappings, "data/target_prediction/multitask/multitask_mappings.csv", row.names = FALSE)
write.csv(all_multitask, "data/target_prediction/multitask/multitask_targets.csv", row.names = FALSE)

# PPB2
ppb_uniprot_ids <- read.table("data/target_prediction/ppb2/ppb2_chembls.txt", row.names = NULL, col.names = NULL)
ppb_mappings <- map_hgnc_all_methods(ppb_uniprot_ids)
all_ppb <- unique(ppb_mappings$HGNC_ID)
all_ppb <- all_ppb[!is.na(all_ppb)]
write.csv(xfp_mappings, "data/target_prediction/ppb2/ppb_mappings.csv", row.names = FALSE)
write.csv(all_ppb, "data/target_prediction/ppb2/ppb_targets.csv", row.names = FALSE)

# Getting intersections 
all_sea <- read_csv("data/target_prediction/sea/sea_targets.csv", show_col_types = FALSE)$x
all_stp <- read_csv("data/target_prediction/stp/stp_targets.csv", show_col_types = FALSE)$Targets
all_ppb <- read_csv("data/target_prediction/ppb2/xfp_targets.csv", show_col_types = FALSE)$x
all_multitask <- read_csv("data/target_prediction/multitask/multitask_targets.csv", show_col_types = FALSE)$x

sets <- list(
  multitask = all_multitask,
  stp = all_stp,
  sea = all_sea,
  ppb = all_ppb,
)

dir.create("data/target_prediction/intersections", recursive = TRUE, showWarnings = FALSE)

# Generate combinations 
for (k in 2:length(sets)) {
  combos <- combn(names(sets), k, simplify = FALSE)
  for (combo in combos) {
    inter <- Reduce(intersect, sets[combo])
    df <- data.frame(target = inter)
    fname <- paste0("data/target_prediction/intersections/intersection_", 
                    paste(combo, collapse = "_"), ".csv")
    write.csv(df, fname, row.names = FALSE)
  }
}
```

# Getting the predicted metabolites/ligands for the intersection genes

```{r}
sea_result <- read_xlsx("data/target_prediction/sea/sea-combined.xlsx")

# Rename columns to avoid special character issues
colnames(sea_result) <- c("Query_ID", "Target_ID", "Affinity_Threshold", "P_Value",
                          "Max_Tc", "Cut_Sum", "Z_Score", "Name", "Description", "Query_Smiles")

# Get only the human targets 
sea_result <- sea_result[grepl("_HUMAN$", sea_result$Target_ID), ]

results <- sea_result[sea_result$Name == "F3", ]
metabolites <- results$Query_ID
```

```{r}
library(readxl)
sea_teng <- read_excel("data/teng1.xlsx", col_names = TRUE)
teng_sea <- unique(sea_teng$Name)
cat(length(unique(sea_teng$Metabolite)), length(unique(sea_teng$`Target ID`)))

stp_teng <- read_excel("data/teng2.xlsx", col_names = TRUE)
teng_stp <- unique(stp_teng$`Common name`)

length(unique(stp_teng$`pubchem ID`))

cat(length(unique(stp_teng$Metabolite)), length(unique(stp_teng$`Common name`)))

length(unique(c(stp_teng$Metabolite, sea_teng$Metabolite)))

teng_i <- read_excel("data/teng3.xlsx", col_names = TRUE)$Common


sea_targets <- read.csv("data/target_prediction/sea/sea_targets.csv")$x
stp_targets <- read.csv("data/target_prediction/stpnovo/stp_targets.csv")$x
```

# Getting metabolites for STP and chemblpred

```{r}
library(readxl)
get_targets_to_metabolites <- function(folder_path) {
  # Listar todos os arquivos CSV
  csv_files <- list.files(path = folder_path, 
                          pattern = "^(cid|nocid).*\\.csv$", 
                          full.names = TRUE)
  
  # Lista final
  targets_to_metabolites <- list()
  
  for (file_path in csv_files) {
    file_name <- basename(file_path)
    
    # Extrair ID do metabólito (cidXXX ou nome completo se for nocid)
    if (grepl("^cid", file_name)) {
      metabolite_id <- sub("cid(.*)\\.csv", "\\1", file_name)
    } else if (grepl("^nocid", file_name)) {
      metabolite_id <- sub("\\.csv$", "", file_name)
    }
    
    # Ignorar arquivos vazios
    if (file.info(file_path)$size == 0) next
    
    # Ler dados
    data <- read.csv(file_path, stringsAsFactors = FALSE)
    
    if (nrow(data) == 0 || !"Common.name" %in% names(data)) next
    
    for (target in data[["Common.name"]]) {
      if (!is.character(target) || is.na(target) || target == "") next
      
      if (is.null(targets_to_metabolites[[target]])) {
        targets_to_metabolites[[target]] <- c()
      }
      
      targets_to_metabolites[[target]] <- c(targets_to_metabolites[[target]], metabolite_id)
    }
  }
  
  return(targets_to_metabolites)
}

target_metabolites_stp <- get_targets_to_metabolites("data/target_prediction/stpnovo")
save(target_metabolites_stp, file="data/target_prediction/stpnovo/target_metabolites_stp.RData")
```

```{r}
library(readxl)
get_targets_to_metabolites <- function(folder_path) {
  # Listar todos os arquivos CSV
  csv_files <- list.files(path = folder_path, 
                          pattern = "^(cid|nocid).*\\.csv$", 
                          full.names = TRUE)
  
  # Lista final
  targets_to_metabolites <- list()
  
  for (file_path in csv_files) {
    file_name <- basename(file_path)
    
    # Extrair ID do metabólito (cidXXX ou nome completo se for nocid)
    if (grepl("^cid", file_name)) {
      metabolite_id <- sub("cid(.*)\\.csv", "\\1", file_name)
    } else if (grepl("^nocid", file_name)) {
      metabolite_id <- sub("\\.csv$", "", file_name)
    }
    
    # print(metabolite_id)
    
    # Ignorar arquivos vazios
    if (file.info(file_path)$size == 0) next
    
    # Ler dados
    prediction_data <- read.csv(file_path, stringsAsFactors = FALSE)
    # print(paste0(file_path, " ", nrow(prediction_data)))
    # print(colnames(prediction_data))
    
    if (nrow(prediction_data) == 0 || !"Target.ChEMBL.ID" %in% names(prediction_data)){
      print(paste0(file_name, "  sem data"))
      next
    } 
    
    for (target in prediction_data[["Target.ChEMBL.ID"]]) {
      # print(target)
      if (!is.character(target) || is.na(target) || target == "") next
      
      if (is.null(targets_to_metabolites[[target]])) {
        targets_to_metabolites[[target]] <- c()
      }
      
      targets_to_metabolites[[target]] <- c(targets_to_metabolites[[target]], metabolite_id)
    }
  }
  
  return(targets_to_metabolites)
}

target_metabolites_chemblpred <- get_targets_to_metabolites("data/target_prediction/chemblpred")
save(target_metabolites_chemblpred, file="data/target_prediction/chemblpred/target_metabolites_chemblpred.RData")
```