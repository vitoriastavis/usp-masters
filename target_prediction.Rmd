---
title: "vitoria-project"
author: "vitoria"
date: "2025-04-02"
output: html_document
---

# Load libraries

```{r message=FALSE, warning=FALSE}
# List of libraries to install
libraries <- c("dplyr", "httr2", "jsonlite", "ggplot2", "readxl", "rvest", 
               "readr", "stringr", "tidyr", "scales", "httr", "xml2", "data.table")




if (!require("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
if (!require("biomaRt", quietly = TRUE)){
  BiocManager::install(c('mygene', 'biomaRt'))
}


# Function to install missing libraries
install_if_missing <- function(lib) {
  if (!require(lib, character.only = TRUE)) {
    install.packages(lib, dependencies = TRUE)
    library(lib, character.only = TRUE)
  }
}

# Apply the function to all libraries
sapply(libraries, install_if_missing)
```

```{r message=FALSE, warning=FALSE}
library(dplyr)
library(httr2)
library(jsonlite)
library(ggplot2)
library(readxl)
# library(rvest)
library(readr)
library(stringr)
library(tidyr)
library(scales)
library(httr)
library(xml2)
library(biomaRt)
library(openxlsx)
library(mygene)
library(data.table)

```

# Target prediction
## Functions to get SMILES from CID

```{r message=FALSE, warning=FALSE}
# Try to get CID from compound name
# If not possible, try to get CID from SID
# Param - name: compound name (character)
# Return - compound_cid: CID (integer)
get_cid <- function(name) {
  if (is.na(name) || name == "") return(NA)  # Handle missing names
  
  encoded_name <- URLencode(name, reserved = TRUE)
  
  # Try getting CID using compound name endpoint
  url_cid <- paste0("https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/name/", 
                    encoded_name, "/cids/JSON")
  response_cid <- tryCatch({
    req <- request(url_cid) |> req_perform()
    if (resp_status(req) == 200) {
      data <- resp_body_json(req)
      if (!is.null(data$IdentifierList$CID)) {
        compound_id <- data$IdentifierList$CID[[1]]
        return(compound_id)  # Return first CID
      }
    }
    return(NA)
  }, error = function(e) return(NA))
  
  # If a CID was found, return it immediately
  if (!is.na(response_cid)) {
    print(paste0("found CID for ", name))
    return(response_cid)
  }
  
  # Pause to respect API rate limits
  Sys.sleep(0.5)  
  
  # Try getting SID using substance name endpoint
  url_sid <- paste0("https://pubchem.ncbi.nlm.nih.gov/rest/pug/substance/name/", encoded_name, "/sids/JSON")
  response_sid <- tryCatch({
    req <- request(url_sid) |> req_perform()
    if (resp_status(req) == 200) {
      data <- resp_body_json(req)
      if (!is.null(data$IdentifierList$SID) && length(data$IdentifierList$SID) > 0) {
        data$IdentifierList$SID[[1]]  # Store the SID 
      } else {
        NA
      }
    } else {
      NA
    }
  }, error = function(e) return(NA))
  
  # Pause to respect API rate limits
  Sys.sleep(0.5)  
  
  # Try getting CID using SID
  url_sid_cid <- paste0("https://pubchem.ncbi.nlm.nih.gov/rest/pug/substance/sid/", 
                        response_sid, "/JSON")
  response_cid <- tryCatch({
    req <- request(url_sid_cid) |> req_perform()
    if (resp_status(req) == 200) {
      data <- resp_body_json(req)
      if (!is.null(data$PC_Substances[[1]]$compound[[2]]$id$id$cid) && length(data$PC_Substances[[1]]$compound[[2]]$id$id$cid) > 0) {
        # print("Found CID using SID") 
        compound_id <- data$PC_Substances[[1]]$compound[[2]]$id$id$cid[[1]]
        print(paste0("found CID for ", name))
        return(compound_id)  # Return CID
      } 
    }
    print(paste0("couldn't find CID for ", name))
    return(NA)
  }, error = function(e) return(NA))
}

library(httr2)
library(jsonlite)

library(httr2)
library(xml2)

get_smiles_from_cid <- function(compound_id) {
  tryCatch({
    if (is.na(compound_id) || compound_id == "") return(NA)

    # URL com /property
    url_property <- paste0("https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/cid/", compound_id, "/property/CanonicalSMILES/JSON")
    req_prop <- request(url_property)

    # Verifica se a URL responde 200 OK
    status_check <- tryCatch({
      req_prop_head <- req_prop |> req_method("HEAD")
      resp_head <- req_perform(req_prop_head)
      resp_status(resp_head)
    }, error = function(e) return(NA))

    if (!is.na(status_check) && status_check == 200) {
      # Faz a requisição completa
      resp <- req_perform(req_prop)
      json <- resp_body_json(resp)
      smiles <- json$PropertyTable$Properties[[1]]$CanonicalSMILES
      if (!is.null(smiles)) return(smiles)
    }
    
    print("nao achei no property, vou no XML")

    # Se a URL não existir ou não retornar smiles → busca no XML
    url_xml <- paste0("https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/cid/", compound_id, "/record/XML")
    req_xml <- request(url_xml)
    resp_xml <- req_perform(req_xml)
    xml <- read_xml(resp_body_string(resp_xml))

    node <- xml_find_first(
      xml,
      "//PC-InfoData[
         PC-InfoData_urn/PC-Urn/PC-Urn_label='SMILES' and
         PC-InfoData_urn/PC-Urn/PC-Urn_name='Absolute'
       ]/PC-InfoData_value/PC-InfoData_value_sval"
    )
    
    print(xml_text(node))

    if (!is.na(node)) return(xml_text(node))

    return(NA)
  }, error = function(e) {
    message("Erro com CID: ", compound_id)
    return(NA)
  })
}


```

## Read and preprocess the data from gutMGene

```{r}
# Read the CSV file from gutMGene
gutmgene1 <- read.csv("data/gutmgene/gutmgene.csv", stringsAsFactors = FALSE)
gutmgene2 <- read.csv("data/gutmgene/gutmgene2.csv", stringsAsFactors = FALSE)

# Rename columns to avoid special character issues
colnames(gutmgene1) <- c("Host_Species", "Gut_Microbe_ID", "Rank",
                        "Metabolite_ID", "Evidence_Type", "Evidence_Amount")
colnames(gutmgene2) <- c("Host_Species", "Metabolite_ID", "Gene_ID",
                        "Alteration", "Evidence_Type", "Evidence_Amount")

# Extract the metabolite name from the "Metabolite_ID" column
# and microbe name from "Gut_Microbe_ID"
gutmgene1 <- gutmgene1 %>%
  mutate(
    Metabolite_Name = str_remove(Metabolite_ID, "\\([^()]*\\)$"), # Removes last set of parentheses and content
    Metabolite_Name = str_trim(Metabolite_Name), # Trims whitespace
    Gut_Microbe_Name = str_extract(Gut_Microbe_ID, "^[^(]+"), # Extracts text before '('
    Gut_Microbe_ID = as.integer(str_extract(Gut_Microbe_ID, "(?<=\\().*(?=\\))")), # Extracts numbers inside '()'
  )

gutmgene2 <- gutmgene2 %>% 
  mutate(
    Metabolite_Name = str_remove(Metabolite_ID, "\\([^()]*\\)$"), # Removes last set of parentheses and content
    Metabolite_Name = str_trim(Metabolite_Name), # Trims whitespace
    Target_Name = str_remove(Gene_ID, "\\([^()]*\\)$")
  )

gutmgene2 <- gutmgene2 %>%
    mutate(Target_Name = str_trim(Target_Name)) # Trims whitespace

# Remove a possibly incorrect microorganism (it's actually an insect)
gutmgene1 <- gutmgene1[!grepl("Bacteria Latreille et al. 1825", gutmgene1$Gut_Microbe_Name), ]
# Remove not identified species
gutmgene1 <- gutmgene1[!grepl("CEBAS", gutmgene1$Gut_Microbe_Name), ]

# Save data with microbe info
save(gutmgene1, file = "data/gutmgene/gutmgene1_beforemerging.RData")  

```

## Build plots of raw data

### Plot 1 - Distribution of genera among metabolites

```{r}
# Count occurrences of each genus
genus_counts <- table(gutmgene$Microbe_Genus)

# Filter to only include genera with frequency > 5
genera_to_keep <- names(genus_counts[genus_counts >= 5])
gutmgene_filtered <- gutmgene[gutmgene$Microbe_Genus %in% genera_to_keep, ]

# Order from most frequent to less frequent
gutmgene_filtered_count <- gutmgene_filtered %>%
  count(Microbe_Genus) %>%
  mutate(Microbe_Genus = reorder(Microbe_Genus, -n))

title_portuguese <- "Distribuição dos microorganismos da microbiota intestinal"
x_axis_portuguese <- "Microorganismo (gênero)"
y_axis_portuguese <- "Número de metabólitos produzidos"

# Create the plot
microbe_distribution <- ggplot(gutmgene_filtered_count,
                               aes(x = Microbe_Genus, y = n)) +
  geom_bar(stat = "identity", fill = "gray30", width = 0.5) +
  theme_minimal() + 
  ggtitle(title_portuguese) +  
  theme(
    plot.title = element_text(size = 18, hjust = 0.5),  
    axis.title.y = element_text(size = 16),
    axis.title.x = element_text(size = 16),
    axis.text.y = element_text(size = 16),
    axis.text.x = element_text(size = 16, angle = 60, hjust = 1),
    panel.grid = element_blank(),  # Remove grid lines
    axis.line.x = element_line(color = "black", linewidth = 0.5),  # Only X-axis line
    axis.line.y = element_line(color = "black", linewidth = 0.5),  # Only Y-axis line
    axis.ticks = element_line(color = "black", linewidth = 1)      # Ensure ticks are visible
  ) +
  labs(x = x_axis_portuguese, 
       y = y_axis_portuguese) +
  scale_y_continuous(breaks = seq(0,max(gutmgene_filtered_count$n),
                                  by = 5))
# Create a directory for plots if it doesn't exist
if (!dir.exists("plots")) {
  dir.create("plots")
}

# Save plot as PNG
png("plots/gutmgene/microbe_distribution.png", width = 800, height = 500)
print(microbe_distribution)
dev.off()
```

## Clean the data

```{r}
# Concatenate dataframes
common_cols <- intersect(names(gutmgene1), names(gutmgene2))
gutmgene <- dplyr::bind_rows(
  dplyr::select(gutmgene1, all_of(common_cols)),
  dplyr::select(gutmgene2, all_of(common_cols))
)

cat("N metabolites (unique):",
    length(unique(gutmgene$Metabolite_ID)), "\n")

# Parse Compound ID (CID) with vectorized function
get_cid_vec <- Vectorize(get_cid)
gutmgene <- gutmgene %>%
  mutate(
    Metabolite_CID = get_cid_vec(Metabolite_Name) # Obtains CID for the metabolite name
  )

# Remove NAs
if (nrow(gutmgene %>% filter(is.na(Metabolite_CID))) != 0) {
  gutmgene_na <- gutmgene %>% filter(is.na(Metabolite_CID))
  gutmgene_clean <- gutmgene %>% filter(!is.na(Metabolite_CID))
  cat("Removed", nrow(gutmgene_na), "Metabolite_CID NAs\n")
} else {
  gutmgene_clean <- gutmgene
  gutmgene_na <- data.frame()
  cat("No Metabolite_CID NAs found\n")
}

# Remove duplicates
gutmgene_nodup <- gutmgene_clean %>%
  distinct(Metabolite_CID, .keep_all=TRUE)
cat("N metabolites without duplicates:", length(gutmgene_nodup$Metabolite_CID), "\n")

# Save processed dataframe
save(gutmgene_nodup, file = "data/gutmgene/gutmgene_nodup.RData")  # No duplicated metabolites
save(gutmgene_na, file = "data/gutmgene/gutmgene_na.RData")        # Only the NAs

# nao lembro aqui
df <- data.frame(name=gutmgene_nodup$Metabolite_Name,
                         CID=gutmgene_nodup$Metabolite_CID,
                         stringsAsFactors=FALSE)

lines <- readLines("data/gutmgene/names_ids.txt")

# Process each line to extract Name and CID
data <- lapply(lines, function(line) {
  parts <- strsplit(line, " ")[[1]]
  cid <- tail(parts, 1)
  name <- paste(head(parts, -1), collapse = " ")
  return(c(name = name, CID = cid))
})

# Convert the result into a data frame
df2 <- as.data.frame(do.call(rbind, data), stringsAsFactors = FALSE)

df3 <- rbind(df, df2)
write.csv(df3, "data/gutmgene/name_cid.csv", row.names = FALSE)

```

## Get SMILES

```{r}
library(httr)
library(jsonlite)

get_smiles_from_pubchem <- function(compound_id) {
  library(httr)
  library(jsonlite)

  url <- paste0("https://pubchem.ncbi.nlm.nih.gov/rest/pug_view/data/compound/", compound_id, "/JSON")
  res <- try(GET(url), silent = TRUE)

  if (inherits(res, "try-error") || status_code(res) != 200) {
    return(NA)
  }

  parsed <- try(fromJSON(content(res, as = "text", encoding = "UTF-8"), simplifyVector = FALSE), silent = TRUE)
  if (inherits(parsed, "try-error") || is.null(parsed$Record$Section)) {
    return(NA)
  }

  find_smiles <- function(sections) {
    for (sec in sections) {
      if (is.list(sec) && !is.null(sec$TOCHeading) && sec$TOCHeading == "SMILES") {
        for (info in sec$Information) {
          val <- info$Value$StringWithMarkup[[1]]$String
          if (!is.null(val)) return(val)
        }
      }
      if (is.list(sec) && !is.null(sec$Section)) {
        found <- find_smiles(sec$Section)
        if (!is.null(found)) return(found)
      }
    }
    return(NULL)
  }

  smiles <- find_smiles(parsed$Record$Section)
  return(ifelse(is.null(smiles), NA, smiles))
}

smiles <- sapply(diff_cid, get_smiles_from_pubchem)
# Create dataframe to store SMILES and CIDs for target prediction
df_smiles_ids <- data.frame(SMILES=smiles,
                         pubchem_ids=paste0("cid", diff_cid),
                         stringsAsFactors=FALSE)
# Save the dataframe as text file
write.table(df_smiles_ids, file="smiles_others.txt",
            row.names=FALSE, col.names=FALSE,
            quote=FALSE, sep=" ")
```

```{r}
# Run the get_smiles_from_cid() for each metabolite CID
smiles <- sapply(gutmgene_nodup$Metabolite_CID, get_smiles_from_cid)
cat(length(smiles), "SMILES were obtained\n")

# Create dataframe to store SMILES and CIDs for target prediction
df_smiles_ids <- data.frame(SMILES=smiles,
                         pubchem_ids=paste0("cid", gutmgene_nodup$Metabolite_CID),
                         stringsAsFactors=FALSE)
# Save the dataframe as text file
write.table(df_smiles_ids, file="smiles_ids.txt",
            row.names=FALSE, col.names=FALSE,
            quote=FALSE, sep=" ")

# Create dataframe to store names and CIDs of the metabolites 
# that are not on PubChem to find the SMILES by the name
df_names_ids <- data.frame(name=gutmgene_na$Metabolite_Name,
                         pubchem_id=paste0("nocid", 1:length(gutmgene_na$Metabolite_Name)),
                         stringsAsFactors=FALSE)
# Save the dataframe as text file
write.table(df_names_ids, file="names_ids.txt",
            row.names=FALSE, col.names=FALSE,
            quote=FALSE, sep=" ")
```

## Parsing SEA results

After running SEA with smiles_ids.txt, read the results.

```{r}
# Read SEA dataframe
original <- read.csv("data/target_prediction/sea/original.xls")
extra <- read.csv("data/target_prediction/sea/extra.xls")
combined <- rbind(original, extra)
# write.xlsx(combined, "data/target_prediction/sea/sea-combined.xlsx")

# Rename columns to avoid special character issues
sea_result <- combined
colnames(sea_result) <- c("Query_ID", "Target_ID", "Affinity_Threshold", "P_Value",
                          "Max_Tc", "Cut_Sum", "Z_Score", "Name", "Description", "Query_Smiles")

# Get only the human targets 
sea_result <- sea_result[grepl("_HUMAN$", sea_result$Target_ID), ]

# Sort the data frame by Target_ID and then by P_Value (ascending)
sea_result <- sea_result[order(sea_result$Target_ID, sea_result$P_Value), ]
# Keep only the first occurrence of each Target_ID (which now has the lowest P_Value)
sea_result <- sea_result[!duplicated(sea_result$Target_ID), ]

sea_targets <- sea_result$Target_ID
sea_targets <- gsub("_HUMAN", "", sea_targets)
cat(length(sea_targets), "targets were predicted with SEA\n")
```

## Parsing STP results

```{r}
# Directory with STP .csv files
directory <- "data/target_prediction/stpnovo"

# Get the files
files <- list.files(path = directory, pattern = "\\.csv$", full.names = TRUE)

# Iterate over the files creating dataframes
dataframes <- list()
for (file_path in files) {
  if (file.info(file_path)$size > 0) {
    df <- read_csv(file_path, show_col_types = FALSE)
    dataframes[[length(dataframes) + 1]] <- df
  } else {
    cat("No targets predicted:", basename(file_path), "\n")
  }
}

# Concatenate dataframes
stp_result <- bind_rows(dataframes)

# Write final dataframe
write_csv(stp_result_extra, file.path(directory, "stp_results.csv"))
```

```{r}
# Read STP dataframe
stp_result <- read.csv("data/target_prediction/stpnovo/stp_results.csv")

# Rename columns to avoid special character issues
colnames(stp_result) <- c("Name", "Common_name", "Uniprot_ID",
                          "ChEMBL_ID", "Class",
                          "Probability", "Known_Actives")

# Remove targets with probability = 0
stp_result <- stp_result[stp_result$Probability != 0, ]

# # Filter the rows with higher probability
stp_result <- stp_result[order(stp_result$Common_name, stp_result$Probability), ]

# Get unique targets
stp_result <- stp_result %>% distinct(Common_name, .keep_all=TRUE)
stp_targets <- stp_result$Common_name  

cat(length(stp_targets), "targets were predicted with STP\n")
```

```{r message=FALSE, warning=FALSE}
library(biomaRt)

biomart_mapping <- function(values, 
                            filters_to_try = NULL,
                            mart = NULL,
                            to_attribute = "hgnc_symbol",
                            verbose = FALSE) {
  # Conecta ao Ensembl se não for passado
  if (is.null(mart)) {
    mart <- useMart("ensembl", dataset = "hsapiens_gene_ensembl")
  }

  # Filtros padrão se não forem especificados
  if (is.null(filters_to_try)) {
    filters_to_try <- c(
      "hgnc_symbol", "chembl", "embl", "entrezgene_id", 
      "ensembl_gene_id", "external_gene_name", 
      "hgnc_id", "hpa_id", "hpa_accession"
    )
  }

  # Lista para guardar os resultados como data frames
  all_results <- list()

  for (filtro in filters_to_try) {
    if (verbose) cat("Tentando filtro:", filtro, "\n")

    res <- tryCatch({
      getBM(
        attributes = c(filtro, to_attribute),
        filters = filtro,
        values = values,
        mart = mart
      )
    }, error = function(e) {
      if (verbose) message("Erro com filtro: ", filtro, " - ", e$message)
      NULL
    })

    if (!is.null(res) && nrow(res) > 0) {
      df <- res
      colnames(df) <- c("Query", "HGNC_ID")
      all_results[[filtro]] <- df
    }
  }

  # Combina tudo em um único data frame
  if (length(all_results) == 0) {
    return(data.frame(Query = character(0), HGNC_ID = character(0)))
  }

  final_df <- do.call(rbind, all_results)
  return(final_df)
}

#######################################################################
library(data.table)

hgnc_dataset_mapping <- function(targets) {
  # Baixar o dataset da HGNC
  hgnc_url <- "https://storage.googleapis.com/public-download-files/hgnc/tsv/tsv/hgnc_complete_set.txt"
  hgnc_file <- tempfile(fileext = ".tsv")
  download.file(hgnc_url, hgnc_file, quiet = TRUE)
  hgnc <- fread(hgnc_file, sep = "\t", quote = "")

  # Função para expandir aliases
  expand_aliases <- function(symbols, main_symbol) {
    if (is.na(symbols)) return(NULL)
    expanded <- unlist(strsplit(symbols, "\\|"))
    data.table(input = toupper(expanded), hgnc_symbol = main_symbol)
  }
  
    # Expandir alias_symbol
  alias_dt <- rbindlist(mapply(expand_aliases, hgnc$alias_symbol, hgnc$symbol, SIMPLIFY = FALSE), fill = TRUE)

  # Expandir prev_symbol
  prev_dt <- rbindlist(mapply(expand_aliases, hgnc$prev_symbol, hgnc$symbol, SIMPLIFY = FALSE), fill = TRUE)

  # Expandir symbol e name diretamente
  symbol_dt <- data.table(input = toupper(hgnc$symbol), hgnc_symbol = hgnc$symbol)
  name_dt   <- data.table(input = toupper(hgnc$name), hgnc_symbol = hgnc$symbol)

   # Unir tudo
  expanded <- rbindlist(list(symbol_dt, alias_dt, prev_dt, name_dt), use.names = TRUE, fill = TRUE)
  expanded <- unique(expanded[!is.na(input)])

  # Normalizar e mapear
  targets_clean <- toupper(trimws(targets))
  mapped <- expanded[input %in% targets_clean]

  # Criar a saída final com o input original
  result <- data.table(Query = mapped$input, HGNC_ID = mapped$hgnc_symbol)
  return(as.data.frame(unique(result)))
}
  
#######################################################################
  
library(hgnc)
library(lubridate)

hgnc_mapping <- function(values, 
                         from_cols = NULL, 
                         to = "symbol", 
                         hgnc_dataset = NULL, 
                         verbose = FALSE) {
  if (is.null(hgnc_dataset)) {
    if (verbose) cat("Importando base HGNC...\n")
    hgnc_dataset <- import_hgnc_dataset()
  }

  if (is.null(from_cols)) {
    from_cols <- c("hgnc_id", "symbol", "name", "entrez_id", "ensembl_gene_id",
    "vega_id", "ucsc_id")
  }

  # Safe wrapper
  safe_crosswalk <- function(value, from, to, hgnc_dataset) {
    tryCatch({
      crosswalk(value = value, from = from, to = to, hgnc_dataset = hgnc_dataset)
    }, error = function(e) {
      if (verbose) message("Erro na coluna ", from, ": ", e$message)
      NULL
    })
  }

  # Lista para guardar resultados (query, id)
  results_list <- list()

  for (col in from_cols) {
    if (verbose) cat("Tentando coluna:", col, "\n")

    for (val in values) {
      res <- safe_crosswalk(val, from = col, to = to, hgnc_dataset = hgnc_dataset)
      if (!is.null(res) && length(res) > 0) {
        results_list[[length(results_list) + 1]] <- data.frame(
          Query = val,
          HGNC_ID = res,
          stringsAsFactors = FALSE
        )
      }
    }
  }

  # Combina tudo e remove duplicatas
  if (length(results_list) == 0) {
    return(data.frame(Query = character(0), HGNC_ID = character(0)))
  }

  final_df <- unique(do.call(rbind, results_list))
  return(final_df)
}

#######################################################################
library(mygene)
mygene_mapping <- function(targets) {
  res <- queryMany(targets, scopes = "symbol,alias,name",
                   fields = "symbol", species = "human")

  df <- data.frame(
    Query = res$query,
    HGNC_ID = res$symbol,
    stringsAsFactors = FALSE
  )

  df <- df[!is.na(df$HGNC_ID), ]
  return(df)
}

#######################################################################

map_hgnc_all_methods <- function(genes, verbose = TRUE) {
  # Run each mapping function with proper error handling
  results <- list()

  # Biomart
  if (verbose) cat("Running biomart_mapping...\n")
  res_biomart <- tryCatch({
    df <- biomart_mapping(genes)
    df$Source <- "biomart"
    df
  }, error = function(e) {
    warning("biomart_mapping failed: ", e$message)
    NULL
  })
  if (!is.null(res_biomart)) results[["biomart"]] <- res_biomart

  # HGNC downloaded dataset
  if (verbose) cat("Running hgnc_dataset_mapping...\n")
  res_dataset <- tryCatch({
    df <- hgnc_dataset_mapping(genes)
    df$Source <- "hgnc_dataset"
    df
  }, error = function(e) {
    warning("hgnc_dataset_mapping failed: ", e$message)
    NULL
  })
  if (!is.null(res_dataset)) results[["hgnc_dataset"]] <- res_dataset

  # hgnc package
  if (verbose) cat("Running hgnc_mapping...\n")
  res_hgnc <- tryCatch({
    df <- hgnc_mapping(genes)
    df$Source <- "hgnc_package"
    df
  }, error = function(e) {
    warning("hgnc_mapping failed: ", e$message)
    NULL
  })
  if (!is.null(res_hgnc)) results[["hgnc_package"]] <- res_hgnc

  # mygene
  if (verbose) cat("Running mygene_mapping...\n")
  res_mygene <- tryCatch({
    df <- mygene_mapping(genes)
    df$Source <- "mygene"
    df
  }, error = function(e) {
    warning("mygene_mapping failed: ", e$message)
    NULL
  })
  if (!is.null(res_mygene)) results[["mygene"]] <- res_mygene

  # Combine all results
  if (length(results) == 0) {
    return(data.frame(Query = character(0), HGNC_ID = character(0), Source = character(0)))
  }

  combined <- do.call(rbind, results)

  return(combined)
}

```

```{r}
sea_mappings <- map_hgnc_all_methods(sea_targets)
all_sea <- unique(sea_mappings$HGNC_ID)
write.csv(sea_mappings, "data/target_prediction/sea/sea_mappings.csv", row.names = FALSE)
write.csv(all_sea, "data/target_prediction/sea/sea_targets.csv", row.names = FALSE)

stp_mappings <- map_hgnc_all_methods(stp_targets)
all_stp <- unique(stp_mappings$HGNC_ID)
write.csv(stp_mappings, "data/target_prediction/stpnovo/stp_mappings.csv", row.names = FALSE)
write.csv(all_stp, "data/target_prediction/stpnovo/stp_targets.csv", row.names = FALSE)

targets_intersection <- intersect(all_sea, all_stp)
save(targets_intersection, file='data/target_prediction/targets_intersection2.RData')

N = 22500
K = length(all_sea)
n = length(all_stp)
k = length(targets_intersection)
  
overlap_hypergeometric <- phyper(k-1, K, N - K, n, lower.tail = FALSE)
```

# Getting the predicted metabolites/ligands for the intersection genes

```{r}
sea_result <- read_xlsx("data/target_prediction/sea/sea-combined.xlsx")

# Rename columns to avoid special character issues
colnames(sea_result) <- c("Query_ID", "Target_ID", "Affinity_Threshold", "P_Value",
                          "Max_Tc", "Cut_Sum", "Z_Score", "Name", "Description", "Query_Smiles")

# Get only the human targets 
sea_result <- sea_result[grepl("_HUMAN$", sea_result$Target_ID), ]

results <- sea_result[sea_result$Name == "F3", ]
metabolites <- results$Query_ID
```

```{r}
library(readxl)
sea_teng <- read_excel("data/teng1.xlsx", col_names = TRUE)
teng_sea <- unique(sea_teng$Name)
cat(length(unique(sea_teng$Metabolite)), length(unique(sea_teng$`Target ID`)))

stp_teng <- read_excel("data/teng2.xlsx", col_names = TRUE)
teng_stp <- unique(stp_teng$`Common name`)

length(unique(stp_teng$`pubchem ID`))

cat(length(unique(stp_teng$Metabolite)), length(unique(stp_teng$`Common name`)))

length(unique(c(stp_teng$Metabolite, sea_teng$Metabolite)))

teng_i <- read_excel("data/teng3.xlsx", col_names = TRUE)$Common


sea_targets <- read.csv("data/target_prediction/sea/sea_targets.csv")$x
stp_targets <- read.csv("data/target_prediction/stpnovo/stp_targets.csv")$x
```
